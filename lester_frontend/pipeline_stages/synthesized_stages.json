{
  "DATAPREP_SYNTHESIZED": "\ndef __dataprep(customers_file, mails_file):\n    import lester as ld\n    import os\n    from transformers import pipeline\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n    import warnings\n\n    warnings.simplefilter(action='ignore', category=FutureWarning)\n\n    target_countries = ['UK', 'DE', 'FR']\n    sentiment_predictor = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n\n    def matches_usecase(text):\n        return \"complaint\" in text or \"bank account\" in text\n\n    def sanitize(text):\n        return text.lower()\n\n    # Read customer data\n    customers_df = ld.read_csv(customers_file, header=None, names=['customer_id', 'customer_email', 'bank', 'country', 'level'], sep=',')\n\n    # Filter for target countries\n    customers_df = customers_df.filter(f'country in {target_countries}')\n\n    # Define is_premium\n    def define_is_premium(level):\n        return level == 'premium'\n    \n    customers_df = customers_df.project('is_premium', ['level'], define_is_premium)\n\n    # Read mails data\n    mails_df = ld.read_csv(mails_file, header=None, names=['mail_id', 'email', 'raw_date', 'mail_subject', 'mail_text'], sep=',')\n\n    # Filter for mails after 2021\n    mails_df = mails_df.filter('int(raw_date.split(\"-\")[0]) >= 2022')\n\n    # Join customers and mails data\n    merged_df = ld.join(mails_df, customers_df, left_on='email', right_on='customer_email')\n\n    # Sanitize mail subject\n    merged_df = merged_df.project('title', ['mail_subject'], lambda mail_subject: sanitize(mail_subject))\n\n    # Sanitize mail text\n    merged_df = merged_df.project('text', ['mail_text'], lambda mail_text: sanitize(mail_text))\n\n    # Predict sentiment\n    def predict_sentiment(mail_text):\n        return sentiment_predictor(mail_text)[0]['label'].lower()\n    \n    merged_df = merged_df.project('sentiment', ['mail_text'], predict_sentiment)\n\n    # Select final columns\n    result_df = merged_df[['title', 'text', 'bank', 'country', 'sentiment', 'is_premium']]\n\n    return result_df\n",
  "FEATURE_SYNTHESIZED": "\ndef __featurise():\n    import numpy as np\n    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n    from sklearn.compose import ColumnTransformer\n    from sentence_transformers import SentenceTransformer\n    from sklearn.base import BaseEstimator, TransformerMixin\n    \n    class SentenceEmbeddingsTransformer(BaseEstimator, TransformerMixin):\n        def __init__(self, model_name=\"all-mpnet-base-v2\"):\n            self.model_name = model_name\n            self.model = SentenceTransformer(model_name)\n        \n        def fit(self, X, y=None):\n            return self\n        \n        def transform(self, X, y=None):\n            return self.model.encode(X)\n    \n    class TitleLengthTransformer(BaseEstimator, TransformerMixin):\n        def fit(self, X, y=None):\n            return self\n        \n        def transform(self, X, y=None):\n            return np.array([len(x) for x in X]).reshape(-1, 1)\n    \n    country_indices = {'DE': 0, 'FR': 1, 'UK': 2}\n    \n    # Define the ColumnTransformer\n    column_transformer = ColumnTransformer(\n        transformers=[\n            ('subject_embeddings', SentenceEmbeddingsTransformer(), 'title'),\n            ('text_embeddings', SentenceEmbeddingsTransformer(), 'text'),\n            ('title_length', StandardScaler(), ['title']),\n            ('country_onehot', OneHotEncoder(categories=[list(country_indices.keys())]), ['country'])\n        ],\n        remainder='drop'\n    )\n    \n    return column_transformer\n\n# Usage:\n# column_transformer = __featurise()\n",
  "MODEL_SYNTHESIZED": "\ndef __model(num_features):\n    import torch\n    import torch.nn as nn\n\n    class LogisticRegressionModel(nn.Module):\n        def __init__(self, num_features):\n            super(LogisticRegressionModel, self).__init__()\n            self.linear = nn.Linear(num_features, 1)\n\n        def forward(self, x):\n            return torch.sigmoid(self.linear(x))\n\n    model = LogisticRegressionModel(num_features)\n    loss = nn.BCELoss()\n\n    return model, loss\n"
}