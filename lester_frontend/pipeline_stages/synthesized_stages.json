{
  "DATAPREP_SYNTHESIZED": "\nimport os\nimport warnings\nimport lester as ld\nfrom transformers import pipeline\n\ndef __dataprep(customers_file, mails_file):\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n    warnings.simplefilter(action='ignore', category=FutureWarning)\n\n    target_countries = ['UK', 'DE', 'FR']\n    sentiment_predictor = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n    \n    def sanitize(text):\n        return text.lower()\n\n    # Read customers data\n    customers_df = ld.read_csv(customers_file, header=None, names=['customer_id', 'customer_email', 'bank', 'country', 'level'], sep=',')\n    \n    # Filter customers based on target countries\n    customers_filtered = customers_df.filter(\"country in @target_countries\")\n    \n    # Create is_premium column\n    def compute_is_premium(level):\n        return level == 'premium'\n    \n    customers_filtered = customers_filtered.project('is_premium', ['level'], compute_is_premium)\n    \n    # Select relevant customer data\n    customer_data = customers_filtered[['customer_email', 'bank', 'country', 'is_premium']]\n    \n    # Read mails data\n    mails_df = ld.read_csv(mails_file, header=None, names=['mail_id', 'email', 'raw_date', 'mail_subject', 'mail_text'], sep=',')\n    \n    # Create mail_year column\n    def extract_year(raw_date):\n        return int(raw_date.split(\"-\")[0])\n    \n    mails_df = mails_df.project('mail_year', ['raw_date'], extract_year)\n    \n    # Filter mails from 2022 onwards\n    mails_filtered = mails_df.filter(\"mail_year >= 2022\")\n    \n    # Join filtered mails with customer data\n    joined_df = ld.join(mails_filtered, customer_data, left_on='email', right_on='customer_email')\n    \n    # Create title column\n    joined_df = joined_df.project('title', ['mail_subject'], sanitize)\n    \n    # Create text column\n    joined_df = joined_df.project('text', ['mail_text'], sanitize)\n    \n    # Create sentiment column\n    def compute_sentiment(mail_text):\n        return sentiment_predictor(mail_text)[0]['label'].lower()\n    \n    joined_df = joined_df.project('sentiment', ['mail_text'], compute_sentiment)\n    \n    # Select final columns\n    result_df = joined_df[['title', 'text', 'bank', 'country', 'sentiment', 'is_premium']]\n    \n    return result_df\n",
  "FEATURE_SYNTHESIZED": "\ndef __featurise():\n    import numpy as np\n    from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n    from sklearn.pipeline import Pipeline, FeatureUnion\n    from sklearn.compose import ColumnTransformer\n    from sentence_transformers import SentenceTransformer\n\n    # Initialize the sentence embedder\n    sentence_embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n\n    # Define transformers\n    def embed_sentences(titles):\n        return sentence_embedder.encode(titles)\n\n    sentence_embedding_transformer = FunctionTransformer(embed_sentences, validate=False)\n\n    def compute_title_length(titles):\n        return np.array([len(title) for title in titles]).reshape(-1, 1)\n\n    title_length_transformer = Pipeline([\n        ('length', FunctionTransformer(compute_title_length, validate=False)),\n        ('scaler', StandardScaler())\n    ])\n\n    country_indices = {'DE': 0, 'FR': 1, 'UK': 2}\n    country_onehot_transformer = OneHotEncoder(categories=[list(country_indices.keys())], sparse_output=False)\n\n    # ColumnTransformer\n    column_transformer = ColumnTransformer(transformers=[\n        ('subject_embeddings', sentence_embedding_transformer, 'title'),\n        ('text_embeddings', sentence_embedding_transformer, 'text'),\n        ('title_length', title_length_transformer, 'title'),\n        ('country_onehot', country_onehot_transformer, ['country'])\n    ])\n\n    return column_transformer\n",
  "MODEL_SYNTHESIZED": "\ndef __model(num_features):\n    import torch\n    import torch.nn as nn\n    \n    class LogisticRegressionModel(nn.Module):\n        def __init__(self, num_features):\n            super(LogisticRegressionModel, self).__init__()\n            self.linear = nn.Linear(num_features, 1)\n        \n        def forward(self, x):\n            return torch.sigmoid(self.linear(x))\n    \n    model = LogisticRegressionModel(num_features)\n    loss = nn.BCELoss()\n    \n    return model, loss\n"
}